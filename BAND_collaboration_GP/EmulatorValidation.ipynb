{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import path\n",
    "from glob import glob\n",
    "import sys\n",
    "import csv\n",
    "sys.path.insert(0, path.abspath('./'))\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from src import workdir, parse_model_parameter_file\n",
    "from src.emulator_BAND import EmulatorBAND\n",
    "from src.emulator import Emulator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to compare multiple GP emulators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_emulators(training_set, model_par, number_test_points, logFlag):\n",
    "    emu1 = EmulatorBAND(training_set, model_par, method='PCGP', logTrafo=logFlag)\n",
    "    emu2 = EmulatorBAND(training_set, model_par, method='PCSK', logTrafo=logFlag)\n",
    "    emu3 = Emulator(training_set, model_par, npc = 4, logTrafo=logFlag)\n",
    "\n",
    "    output_emu1 = emu1.testEmulatorErrors(number_test_points=number_test_points)\n",
    "    emu_pred_1 = output_emu1[0]\n",
    "    emu_pred_err_1 = output_emu1[1]\n",
    "    vali_data_1 = output_emu1[2]\n",
    "    vali_data_err_1 = output_emu1[3]\n",
    "\n",
    "    output_emu2 = emu2.testEmulatorErrors(number_test_points=number_test_points)\n",
    "    emu_pred_2 = output_emu2[0]\n",
    "    emu_pred_err_2 = output_emu2[1]\n",
    "    vali_data_2 = output_emu2[2]\n",
    "    vali_data_err_2 = output_emu2[3]\n",
    "\n",
    "    output_emu3 = emu3.testEmulatorErrors(nTestPoints=number_test_points)\n",
    "    emu_pred_3 = output_emu3[0]\n",
    "    emu_pred_err_3 = output_emu3[1]\n",
    "    vali_data_3 = output_emu3[2]\n",
    "    vali_data_err_3 = output_emu3[3]\n",
    "\n",
    "    nObs = vali_data_1.shape[1]  # Assuming all datasets have the same number of observables\n",
    "\n",
    "    X1_obs = []\n",
    "    X2_obs = []\n",
    "    X3_obs = []\n",
    "    mean_emulator_pred_err_obs_1 = []\n",
    "    mean_emulator_pred_err_obs_2 = []\n",
    "    mean_emulator_pred_err_obs_3 = []\n",
    "    moments_X1 = []\n",
    "    moments_X2 = []\n",
    "    moments_X3 = []\n",
    "    for obsIdx in range(nObs):\n",
    "        X1 = (emu_pred_1[:, obsIdx] - vali_data_1[:, obsIdx]) / emu_pred_err_1[:, obsIdx]\n",
    "        X2 = (emu_pred_2[:, obsIdx] - vali_data_2[:, obsIdx]) / emu_pred_err_2[:, obsIdx]\n",
    "        X3 = (emu_pred_3[:, obsIdx] - vali_data_3[:, obsIdx]) / emu_pred_err_3[:, obsIdx]\n",
    "        X1_obs.append(X1)\n",
    "        X2_obs.append(X2)\n",
    "        X3_obs.append(X3)\n",
    "        mean_emulator_pred_err_obs_1.extend([np.mean(emu_pred_err_1[:, obsIdx]/emu_pred_1[:, obsIdx])])\n",
    "        mean_emulator_pred_err_obs_2.extend([np.mean(emu_pred_err_2[:, obsIdx]/emu_pred_2[:, obsIdx])])\n",
    "        mean_emulator_pred_err_obs_3.extend([np.mean(emu_pred_err_3[:, obsIdx]/emu_pred_3[:, obsIdx])])\n",
    "\n",
    "        # Compute first four moments of the distributions\n",
    "        mean1 = np.mean(X1)\n",
    "        variance1 = np.mean((X1 - mean1)**2.)\n",
    "        skewness1 = np.mean((X1 - mean1)**3.) / variance1**(3./2.)\n",
    "        kurtosis1 = np.mean((X1 - mean1)**4.) / variance1**(4./2.) - 3.\n",
    "        moments1 = (mean1, variance1, skewness1, kurtosis1)\n",
    "        moments_X1.append(moments1)\n",
    "\n",
    "        mean2 = np.mean(X2)\n",
    "        variance2 = np.mean((X2 - mean2)**2.)\n",
    "        skewness2 = np.mean((X2 - mean2)**3.) / variance2**(3./2.)\n",
    "        kurtosis2 = np.mean((X2 - mean2)**4.) / variance2**(4./2.) - 3.\n",
    "        moments2 = (mean2, variance2, skewness2, kurtosis2)\n",
    "        moments_X2.append(moments2)\n",
    "\n",
    "        mean3 = np.mean(X3)\n",
    "        variance3 = np.mean((X3 - mean3)**2.)\n",
    "        skewness3 = np.mean((X3 - mean3)**3.) / variance3**(3./2.)\n",
    "        kurtosis3 = np.mean((X3 - mean3)**4.) / variance3**(4./2.) - 3.\n",
    "        moments3 = (mean3, variance3, skewness3, kurtosis3)\n",
    "        moments_X3.append(moments3)\n",
    "\n",
    "    return (X1_obs,X2_obs,X3_obs), (moments_X1,moments_X2,moments_X3), (mean_emulator_pred_err_obs_1,mean_emulator_pred_err_obs_2,mean_emulator_pred_err_obs_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write functions for the output of the different GP's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output_to_csv_mean_emu_err(filename, data):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for row in data:\n",
    "            writer.writerow([row])\n",
    "\n",
    "def write_output_to_csv_moments_and_X(filename, data):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "def train_multiple_emulators_and_write_to_csv(training_set, model_par, number_test_points, output_file, logFlag):\n",
    "    # Your existing function code...\n",
    "    (X1_obs, X2_obs, X3_obs), (moments_X1, moments_X2, moments_X3), (mean_emulator_pred_err_obs_1, mean_emulator_pred_err_obs_2, mean_emulator_pred_err_obs_3) = train_multiple_emulators(training_set, model_par, number_test_points, logFlag)\n",
    "    \n",
    "    # Write X1_obs, X2_obs, X3_obs to CSV\n",
    "    write_output_to_csv_moments_and_X(output_file + f'_{number_test_points}_X1_obs.dat', X1_obs)\n",
    "    write_output_to_csv_moments_and_X(output_file + f'_{number_test_points}_X2_obs.dat', X2_obs)\n",
    "    write_output_to_csv_moments_and_X(output_file + f'_{number_test_points}_X3_obs.dat', X3_obs)\n",
    "\n",
    "    # Write moments_X1, moments_X2, moments_X3 to CSV\n",
    "    write_output_to_csv_moments_and_X(output_file + f'_{number_test_points}_moments_X1.dat', moments_X1)\n",
    "    write_output_to_csv_moments_and_X(output_file + f'_{number_test_points}_moments_X2.dat', moments_X2)\n",
    "    write_output_to_csv_moments_and_X(output_file + f'_{number_test_points}_moments_X3.dat', moments_X3)\n",
    "\n",
    "    # Write mean_emulator_pred_err_obs_1, mean_emulator_pred_err_obs_2, mean_emulator_pred_err_obs_3 to CSV\n",
    "    write_output_to_csv_mean_emu_err(output_file + f'_{number_test_points}_mean_emulator_pred_err_obs_1.dat', mean_emulator_pred_err_obs_1)\n",
    "    write_output_to_csv_mean_emu_err(output_file + f'_{number_test_points}_mean_emulator_pred_err_obs_2.dat', mean_emulator_pred_err_obs_2)\n",
    "    write_output_to_csv_mean_emu_err(output_file + f'_{number_test_points}_mean_emulator_pred_err_obs_3.dat', mean_emulator_pred_err_obs_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read functions for the different file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emulator_file_errors(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(float(line.strip()))\n",
    "    return data\n",
    "\n",
    "def read_emulator_file_moments(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            values = line.strip().split(',')\n",
    "            data.append([float(value) for value in values])\n",
    "    return data\n",
    "\n",
    "def read_multiple_emulator_errors_files(number_test_points_list,filename):\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    data_list3 = []\n",
    "    for i in number_test_points_list:\n",
    "        filename1 = f\"./emulator_output/{filename}_{i}_mean_emulator_pred_err_obs_1.dat\"\n",
    "        data1 = read_emulator_file_errors(filename1)\n",
    "        data_list1.append(data1)\n",
    "\n",
    "        filename2 = f\"./emulator_output/{filename}_{i}_mean_emulator_pred_err_obs_2.dat\"\n",
    "        data2 = read_emulator_file_errors(filename2)\n",
    "        data_list2.append(data2)\n",
    "\n",
    "        filename3 = f\"./emulator_output/{filename}_{i}_mean_emulator_pred_err_obs_3.dat\"\n",
    "        data3 = read_emulator_file_errors(filename3)\n",
    "        data_list3.append(data3)\n",
    "    return (data_list1,data_list2,data_list3)\n",
    "\n",
    "def read_multiple_moments_files(number_test_points_list,filename):\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    data_list3 = []\n",
    "    for i in number_test_points_list:\n",
    "        filename1 = f\"./emulator_output/{filename}_{i}_moments_X1.dat\"\n",
    "        data1 = read_emulator_file_moments(filename1)\n",
    "        data_list1.append(data1)\n",
    "\n",
    "        filename2 = f\"./emulator_output/{filename}_{i}_moments_X2.dat\"\n",
    "        data2 = read_emulator_file_moments(filename2)\n",
    "        data_list2.append(data2)\n",
    "\n",
    "        filename3 = f\"./emulator_output/{filename}_{i}_moments_X3.dat\"\n",
    "        data3 = read_emulator_file_moments(filename3)\n",
    "        data_list3.append(data3)\n",
    "    return (data_list1, data_list2, data_list3)\n",
    "\n",
    "def read_multiple_X_files(number_test_points_list,filename):\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    data_list3 = []\n",
    "    for i in number_test_points_list:\n",
    "        filename1 = f\"./emulator_output/{filename}_{i}_X1_obs.dat\"\n",
    "        data1 = read_emulator_file_moments(filename1)\n",
    "        data_list1.append(data1)\n",
    "\n",
    "        filename2 = f\"./emulator_output/{filename}_{i}_X2_obs.dat\"\n",
    "        data2 = read_emulator_file_moments(filename2)\n",
    "        data_list2.append(data2)\n",
    "\n",
    "        filename3 = f\"./emulator_output/{filename}_{i}_X3_obs.dat\"\n",
    "        data3 = read_emulator_file_moments(filename3)\n",
    "        data_list3.append(data3)\n",
    "    return (data_list1, data_list2, data_list3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot functions for the read files. These plots are customized for the dNdy data set with 21 observables. The format might need a change for the other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emulator_errors_combined(err1, err2, err3, number_training_points, filename, plotformat):\n",
    "    rows = plotformat[0]\n",
    "    cols = plotformat[1]\n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 20))  # Create subplots\n",
    "    \n",
    "    for i in range(rows):  # Rows\n",
    "        for j in range(cols):  # Columns\n",
    "            idx = i * cols + j\n",
    "            axs[i, j].plot(number_training_points, [err[idx] for err in err1], label=\"PCGP\")\n",
    "            axs[i, j].plot(number_training_points, [err[idx] for err in err2], label=\"PCSK\")\n",
    "            axs[i, j].plot(number_training_points, [err[idx] for err in err3], label=\"Scikit GP\")\n",
    "            axs[i, j].set_title(f\"Observable {idx+1}\")\n",
    "            if i == 0 and j == 0:\n",
    "                axs[i, j].legend()\n",
    "            #axs[i, j].set_yscale('log')\n",
    "            if i == rows-1:  # Set x label for bottom row\n",
    "                axs[i, j].set_xlabel(\"Training Points\")\n",
    "            if j == 0:  # Set y label for leftmost column\n",
    "                axs[i, j].set_ylabel(\"Mean Emulator Uncertainty\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename+\".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_emulator_moments_combined(mom1, mom2, mom3, number_training_points, filename, plotformat):\n",
    "    rows = plotformat[0]\n",
    "    cols = plotformat[1]\n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 20))  # Create subplots\n",
    "    for i in range(rows):  # Rows\n",
    "        for j in range(cols):  # Columns\n",
    "            idx = i * cols + j\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][0] for mom in mom1], label=\"PCGP\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][0] for mom in mom2], label=\"PCSK\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][0] for mom in mom3], label=\"Scikit GP\")\n",
    "            axs[i, j].set_title(f\"Observable {idx+1}\")\n",
    "            if i == 0 and j == 0:\n",
    "                axs[i, j].legend()\n",
    "            if i == rows-1:  # Set x label for bottom row\n",
    "                axs[i, j].set_xlabel(\"Training Points\")\n",
    "            if j == 0:  # Set y label for leftmost column\n",
    "                axs[i, j].set_ylabel(\"Mean X\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename+\"_mean.pdf\")\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 20))  # Create subplots\n",
    "    for i in range(rows):  # Rows\n",
    "        for j in range(cols):  # Columns\n",
    "            idx = i * cols + j\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][1] for mom in mom1], label=\"PCGP\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][1] for mom in mom2], label=\"PCSK\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][1] for mom in mom3], label=\"Scikit GP\")\n",
    "            axs[i, j].set_title(f\"Observable {idx+1}\")\n",
    "            if i == 0 and j == 0:\n",
    "                axs[i, j].legend()\n",
    "            if i == rows-1:  # Set x label for bottom row\n",
    "                axs[i, j].set_xlabel(\"Training Points\")\n",
    "            if j == 0:  # Set y label for leftmost column\n",
    "                axs[i, j].set_ylabel(\"Variance X\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename+\"_variance.pdf\")\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 20))  # Create subplots\n",
    "    for i in range(rows):  # Rows\n",
    "        for j in range(cols):  # Columns\n",
    "            idx = i * cols + j\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][2] for mom in mom1], label=\"PCGP\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][2] for mom in mom2], label=\"PCSK\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][2] for mom in mom3], label=\"Scikit GP\")\n",
    "            axs[i, j].set_title(f\"Observable {idx+1}\")\n",
    "            if i == 0 and j == 0:\n",
    "                axs[i, j].legend()\n",
    "            if i == rows-1:  # Set x label for bottom row\n",
    "                axs[i, j].set_xlabel(\"Training Points\")\n",
    "            if j == 0:  # Set y label for leftmost column\n",
    "                axs[i, j].set_ylabel(\"Skewness X\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename+\"_skewness.pdf\")\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 20))  # Create subplots\n",
    "    for i in range(rows):  # Rows\n",
    "        for j in range(cols):  # Columns\n",
    "            idx = i * cols + j\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][3] for mom in mom1], label=\"PCGP\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][3] for mom in mom2], label=\"PCSK\")\n",
    "            axs[i, j].plot(number_training_points, [mom[idx][3] for mom in mom3], label=\"Scikit GP\")\n",
    "            axs[i, j].set_title(f\"Observable {idx+1}\")\n",
    "            if i == 0 and j == 0:\n",
    "                axs[i, j].legend()\n",
    "            if i == rows-1:  # Set x label for bottom row\n",
    "                axs[i, j].set_xlabel(\"Training Points\")\n",
    "            if j == 0:  # Set y label for leftmost column\n",
    "                axs[i, j].set_ylabel(\"Excess Kurtosis X\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename+\"_kurtosis.pdf\")\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "def plot_emulator_X_combined(X1, X2, X3, filename, plotformat):\n",
    "    rows = plotformat[0]\n",
    "    cols = plotformat[1]\n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(10, 20))  # Create subplots\n",
    "    \n",
    "    x = np.linspace(-5, 5, 300)\n",
    "    y = (1 / (np.sqrt(2*np.pi))) * np.exp(-0.5 * x**2)\n",
    "    for i in range(rows):  # Rows\n",
    "        for j in range(cols):  # Columns\n",
    "            idx = i * cols + j\n",
    "            axs[i, j].hist(X1[idx], density=True, histtype='step', label=\"PCGP\")\n",
    "            axs[i, j].hist(X2[idx], density=True, histtype='step', label=\"PCSK\")\n",
    "            axs[i, j].hist(X3[idx], density=True, histtype='step',  label=\"Scikit GP\")\n",
    "            axs[i, j].set_title(f\"Observable {idx+1}\")\n",
    "            if i == 0 and j == 0:\n",
    "                axs[i, j].legend()\n",
    "            if i == rows-1:  # Set x label for bottom row\n",
    "                axs[i, j].set_xlabel(\"X\")\n",
    "            if j == 0:  # Set y label for leftmost column\n",
    "                axs[i, j].set_ylabel(\"p(X)\")\n",
    "\n",
    "            axs[i, j].plot(x, y, color = 'black', zorder = -2, linewidth = 2, label = 'Normal dist.')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename+\".pdf\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data files for a different number of test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_par = \"../data/modelDesign_3DMCGlauber.txt\"\n",
    "\n",
    "training_set_list_dNdy = [\"../data/AuAu7.7_dNdy.pkl\",\"../data/AuAu19p6_dNdy.pkl\",\"../data/AuAu200_dNdy.pkl\",\"../data/AuAu200_PHOBOSdNdeta.pkl\"]\n",
    "output_file_list_dNdy = [\"./emulator_output/7p7_dNdy_emu_out\",\"./emulator_output/19p6_dNdy_emu_out\",\"./emulator_output/200_dNdy_emu_out\",\"./emulator_output/200PHOBOS_dNdeta_emu_out\"]\n",
    "output_file_list_LOGdNdy = [\"./emulator_output/7p7_LOGdNdy_emu_out\",\"./emulator_output/19p6_LOGdNdy_emu_out\",\"./emulator_output/200_LOGdNdy_emu_out\",\"./emulator_output/200PHOBOS_LOGdNdeta_emu_out\"]\n",
    "\n",
    "training_set_list_pTvn = [\"../data/AuAu7.7_pTvn.pkl\",\"../data/AuAu19p6_pTvn.pkl\",\"../data/AuAu200_pTvn.pkl\", \"../data/AuAu200_PHOBOSv2eta.pkl\"]\n",
    "output_file_list_pTvn = [\"./emulator_output/7p7_pTvn_emu_out\",\"./emulator_output/19p6_pTvn_emu_out\",\"./emulator_output/200_pTvn_emu_out\",\"./emulator_output/200PHOBOS_vn_emu_out\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick summary:\n",
    "- The AuAu7.7_dNdy data set does not sort out any of the 1000 training points.\n",
    "- The AuAu7.7_pTvn data set sorts out 40 of the 1000 training points due to large statistical errors.\n",
    "- The AuAu19p6_dNdy data set does not sort out any of the 1100 training points.\n",
    "- The AuAu19p6_pTvn data set sorts out 5 of the 1100 training points due to large statistical errors.\n",
    "- The AuAu200_dNdy data set does not sort out any of the 1100 training points.\n",
    "- The AuAu200_pTvn data set sorts out 46 of the 1100 training points due to large statistical errors.\n",
    "- The AuAu200_PHOBOS_dNdeta data set sorts out 1 of the 1000 training points due to large statistical errors.\n",
    "- The AuAu200_PHOBOSv2eta data set does not sort out any of the 1100 training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [900,800,700,600,500,400,300,200,100]:\n",
    "    for tr_set in range(len(training_set_list_dNdy)):\n",
    "        train_multiple_emulators_and_write_to_csv(training_set_list_dNdy[tr_set], model_par, i, output_file_list_dNdy[tr_set], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [900,800,700,600,500,400,300,200,100]:\n",
    "    for tr_set in range(len(training_set_list_dNdy)):\n",
    "        train_multiple_emulators_and_write_to_csv(training_set_list_dNdy[tr_set], model_par, i, output_file_list_LOGdNdy[tr_set], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [900,800,700,600,500,400,300,200,100]:\n",
    "    for tr_set in range(len(training_set_list_pTvn)):\n",
    "        train_multiple_emulators_and_write_to_csv(training_set_list_pTvn[tr_set], model_par, i, output_file_list_pTvn[tr_set], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files for different numbers of test points and plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_prefix = \"7p7_dNdy_emu_out\"\n",
    "#filename_prefix = \"19p6_dNdy_emu_out\"\n",
    "#filename_prefix = \"200_dNdy_emu_out\"\n",
    "#filename_prefix = \"200PHOBOS_dNdeta_emu_out\"\n",
    "\n",
    "#filename_prefix = \"7p7_LOGdNdy_emu_out\"\n",
    "#filename_prefix = \"19p6_LOGdNdy_emu_out\"\n",
    "#filename_prefix = \"200_LOGdNdy_emu_out\"\n",
    "#filename_prefix = \"200PHOBOS_LOGdNdeta_emu_out\"\n",
    "\n",
    "#filename_prefix = \"7p7_pTvn_emu_out\"\n",
    "#filename_prefix = \"19p6_pTvn_emu_out\"\n",
    "#filename_prefix = \"200_pTvn_emu_out\"\n",
    "#filename_prefix = \"200PHOBOS_vn_emu_out\"\n",
    "\n",
    "#[900,800,700,600,500,400,300,200,100]\n",
    "err1, err2, err3 = read_multiple_emulator_errors_files([900,800],filename_prefix)\n",
    "mom1, mom2, mom3 = read_multiple_moments_files([900,800],filename_prefix)\n",
    "X1, X2, X3 = read_multiple_X_files([900,800],filename_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[60,160,260,360,460,560,660,760,860]\n",
    "#[195,295,395,495,595,695,795,895,995]\n",
    "#[200,300,400,500,600,700,800,900,1000]\n",
    "#[154,254,354,454,554,654,754,854,954]\n",
    "#[99,199,299,399,499,599,699,799,899]\n",
    "plot_emulator_errors_combined(err1,err2,err3,[100,200,300,400,500,600,700,800,900],\"./AuAu7p7_emu_uncertainty_dNdy\",(7,3))\n",
    "plot_emulator_moments_combined(mom1,mom2,mom3,[100,200,300,400,500,600,700,800,900],\"./AuAu7p7_emu_moment_dNdy\",(7,3))\n",
    "plot_emulator_X_combined(X1[-1],X2[-1],X3[-1],\"./AuAu7p7_emu_Xhist_dNdy_200trainingpoints\",(7,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emulator_vs_truth(vali_data,vali_data_err,emu_pred,emu_pred_err):\n",
    "    nValidationPoints, nObs = vali_data_1.shape\n",
    "\n",
    "    for obsIdx in range(nObs):\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes([0.12, 0.12, 0.83, 0.83])\n",
    "        plt.errorbar(vali_data[:, obsIdx], emu_pred[:, obsIdx],\n",
    "                    yerr=np.sqrt(emu_pred_err[:, obsIdx,obsIdx]),\n",
    "                    xerr=vali_data_err[:, obsIdx],\n",
    "                    marker=\"o\", linestyle=\"\")\n",
    "        plt.plot([-200, 200], [-200, 200], '--k')\n",
    "        plt.xlim([vali_data[:, obsIdx].min() - 1,\n",
    "                vali_data[:, obsIdx].max() + 1])\n",
    "        plt.ylim([emu_pred[:, obsIdx].min() - 1,\n",
    "                emu_pred[:, obsIdx].max() + 1])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.text(0.05, 0.95, \"obs {}\".format(obsIdx), fontsize=20, transform=ax.transAxes, verticalalignment='top')\n",
    "        plt.xlabel(\"truth\")\n",
    "        plt.ylabel(\"emulator results\")\n",
    "\n",
    "def plot_emulator_vs_truth_relative(vali_data,vali_data_err,emu_pred,emu_pred_err):\n",
    "    nValidationPoints, nObs = vali_data.shape\n",
    "\n",
    "    for obsIdx in range(nObs):\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes([0.12, 0.12, 0.83, 0.83])\n",
    "        plt.plot(range(len(vali_data)),\n",
    "                (emu_pred[:, obsIdx] - vali_data[:, obsIdx])/np.sqrt(vali_data_err[:, obsIdx]**2.+ emu_pred_err[:, obsIdx, obsIdx]),\n",
    "                marker=\"o\", linestyle=\"\")\n",
    "        plt.fill_between([-nValidationPoints, nValidationPoints], [2, 2], [-2, -2], color='g', alpha=0.2)\n",
    "        plt.xlim([-1,len(vali_data)+1])\n",
    "        plt.ylim([-4, 4])\n",
    "        ax.text(0.05, 0.95, \"obs {}\".format(obsIdx), fontsize=20, transform=ax.transAxes, verticalalignment='top')\n",
    "        plt.xlabel(\"test point\")\n",
    "        plt.ylabel(\"relative diff. [$\\sigma$]\")\n",
    "\n",
    "def plot_histogram_emulator_vs_truth_relative(vali_data_list,emu_pred_list,emu_pred_err_list,dataset_labels=None):\n",
    "    if not isinstance(vali_data_list, list):\n",
    "        vali_data_list = [vali_data_list]\n",
    "    if not isinstance(emu_pred_list, list):\n",
    "        emu_pred_list = [emu_pred_list]\n",
    "    if not isinstance(emu_pred_err_list, list):\n",
    "        emu_pred_err_list = [emu_pred_err_list]\n",
    "    if not isinstance(dataset_labels, list):\n",
    "        dataset_labels = [dataset_labels]\n",
    "    \n",
    "    nObs = vali_data_list[0].shape[1]  # Assuming all datasets have the same number of observables\n",
    "\n",
    "    for obsIdx in range(nObs):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xlabel(\"A = (GP-truth)/GPerr\")\n",
    "        ax.set_ylabel(\"p(A)\")\n",
    "        \n",
    "        moments = []\n",
    "        handles = []\n",
    "        for vali_data, emu_pred, emu_pred_err, label in zip(vali_data_list, emu_pred_list, emu_pred_err_list, dataset_labels):\n",
    "            A = (emu_pred[:, obsIdx] - vali_data[:, obsIdx]) / np.sqrt(emu_pred_err[:, obsIdx, obsIdx])\n",
    "            ax.hist(A, bins=25, density=True, histtype='step', label=label)\n",
    "\n",
    "            # Compute first four moments of the histogram\n",
    "            mean = np.mean(A)\n",
    "            variance = np.mean((A - mean)**2.)\n",
    "            skewness = np.mean((A - mean)**3.) / variance**(3./2.)\n",
    "            kurtosis = np.mean((A - mean)**4.) / variance**(4./2.)\n",
    "            moment_string = f'μ={mean:.2f}, σ²= {variance:.2f}, γ₁={skewness:.2f}, γ₂={kurtosis:.2f}'\n",
    "            moments.append((label, moment_string))\n",
    "\n",
    "            patch = mpatches.Patch(color='none', label=label)\n",
    "            handles.append(patch)\n",
    "\n",
    "        x = np.linspace(-6, 6, 300)\n",
    "        y = (1 / (np.sqrt(2*np.pi))) * np.exp(-0.5 * x**2)        \n",
    "        plt.plot(x, y, color = 'black', zorder = 2, linewidth = 2, label = 'Normal dist.')\n",
    "\n",
    "        ax.text(0.05, 0.8, \"obs {}\".format(obsIdx), fontsize=20, transform=ax.transAxes, verticalalignment='top')\n",
    "        ax.legend()\n",
    "\n",
    "        # Add a separate legend for the moment strings\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.legend(handles, moments, loc='upper left', fontsize=6)\n",
    "        ax2.axis('off')  # Turn off the axis for the second legend\n",
    "        plt.tight_layout() \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
